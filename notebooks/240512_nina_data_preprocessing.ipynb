{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T15:26:04.088107200Z",
     "start_time": "2024-05-13T15:26:03.976004700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T15:26:04.222102700Z",
     "start_time": "2024-05-13T15:26:04.088107200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Topic: EX2 - Turbofan RUL Prediction\n",
    "**Task**: Predict the remaining useful life (RUL) of turbofan engines based on given sensor data (time series data). It is a regression problem.\n",
    "**Data**: Turbofan engine degradation simulation data (NASA) - [Link](https://data.nasa.gov/dataset/Turbofan-Engine-Degradation-Simulation-Data-Set/vrks-gjie). See also in the topic [introduction notebook](https://github.com/nina-prog/damage-propagation-modeling/blob/2fb8c1a1102a48d7abbf04e4031807790a913a99/notebooks/Turbofan%20remaining%20useful%20life%20Prediction.ipynb).\n",
    "\n",
    "**Subtasks**:\n",
    "1. Perform a deep **exploratory data analysis (EDA)** on the given data.\n",
    "2. Implement a more efficient **sliding window method** for time series data analysis.\n",
    "3. Apply **traditional machine learning methods** (SOTA) to predict the remaining useful life. Includes data preparation, feature extraction, feature selection, model selection, and model parameter optimization. -> ðŸŽ¯ **Focus on this task** data preparation and feature selection (feature extraction part of sliding window method).\n",
    "4. Create **neural network models** to predict the remaining useful life. Includes different architectures like Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), or Attention Models. Note: You can search for SOTA research papers and reproduce current state-of-the-art models.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports + Settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# third-party libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import List, Union\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T15:51:55.823844300Z",
     "start_time": "2024-05-13T15:51:55.722263100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# source code\n",
    "from src.utils import load_data, load_config\n",
    "from src.data_preprocessing import create_rolling_windows_datasets\n",
    "from src.data_cleaning import identify_missing_values, identify_single_unique_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T17:07:21.618934800Z",
     "start_time": "2024-05-13T17:07:21.434612300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Set2\")\n",
    "sns.set(rc={\"figure.dpi\":100, 'savefig.dpi':200})\n",
    "sns.set_context('notebook')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T15:26:05.731130600Z",
     "start_time": "2024-05-13T15:26:05.636584200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T15:26:05.826159100Z",
     "start_time": "2024-05-13T15:26:05.716210Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "os.chdir(\"../\") # set working directory to root of project\n",
    "#os.getcwd() # check current working directory"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T15:26:05.905696900Z",
     "start_time": "2024-05-13T15:26:05.816052700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "PATH_TO_CONFIG = \"configs/config.yaml\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T15:26:06.001109800Z",
     "start_time": "2024-05-13T15:26:05.896117800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load config + Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "config = load_config(PATH_TO_CONFIG) # config is dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T15:39:25.989524200Z",
     "start_time": "2024-05-13T15:39:25.889635200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-13 17:26:06 [\u001B[34msrc.utils:56\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Loading data set 1...\u001B[0m\n",
      "2024-05-13 17:26:06 [\u001B[34msrc.utils:85\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Loaded raw data for dataset 1.\u001B[0m\n",
      "2024-05-13 17:26:06 [\u001B[34msrc.utils:86\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Train Data: (20631, 26)\u001B[0m\n",
      "2024-05-13 17:26:06 [\u001B[34msrc.utils:87\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Test Data: (13096, 26)\u001B[0m\n",
      "2024-05-13 17:26:06 [\u001B[34msrc.utils:88\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Test RUL Data: (100, 1)\u001B[0m\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 325 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data, test_data, test_RUL_data = load_data(config_path=PATH_TO_CONFIG, dataset_num=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T15:26:06.485207500Z",
     "start_time": "2024-05-13T15:26:06.066242Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-13 17:39:27 [\u001B[34msrc.data_preprocessing:61\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Creating rolling windows for train data...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:05<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-13 17:39:33 [\u001B[34msrc.data_preprocessing:65\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Extracting features for train data...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:08<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-13 17:40:55 [\u001B[34msrc.data_preprocessing:73\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Calculating target for train data...\u001B[0m\n",
      "2024-05-13 17:40:55 [\u001B[34msrc.data_preprocessing:80\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Creating rolling windows for test data...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:04<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-13 17:40:59 [\u001B[34msrc.data_preprocessing:86\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Extracting features for test data...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:02<00:00, 14.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-13 17:41:02 [\u001B[34msrc.data_preprocessing:94\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Matching target index with test data...\u001B[0m\n",
      "2024-05-13 17:41:02 [\u001B[34msrc.data_preprocessing:98\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Datasets created successfully.\u001B[0m\n",
      "2024-05-13 17:41:02 [\u001B[34msrc.data_preprocessing:99\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Shape of X_train: (20131, 240)\u001B[0m\n",
      "2024-05-13 17:41:02 [\u001B[34msrc.data_preprocessing:100\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Shape of y_train: (20131, 1)\u001B[0m\n",
      "2024-05-13 17:41:02 [\u001B[34msrc.data_preprocessing:101\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Shape of X_test: (100, 240)\u001B[0m\n",
      "2024-05-13 17:41:02 [\u001B[34msrc.data_preprocessing:102\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Shape of y_test: (100, 1)\u001B[0m\n",
      "CPU times: total: 27.3 s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, y_train, X_test, y_test = create_rolling_windows_datasets(train_data, test_data, test_RUL_data, column_id=\"UnitNumber\", column_sort=\"Cycle\", max_timeshift=config[\"preprocessing\"][\"max_window_size\"], min_timeshift=config[\"preprocessing\"][\"min_window_size\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T15:41:02.789448500Z",
     "start_time": "2024-05-13T15:39:27.499329600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load saved preprocessed data from pickle\n",
    "#X_train = pd.read_pickle(\"data/processed/ex2_X_train_20240512-155504.pkl\")\n",
    "#y_train = pd.read_pickle(\"data/processed/ex2_y_train_20240512-155504.pkl\")\n",
    "#X_test = pd.read_pickle(\"data/processed/ex2_X_test_20240512-155504.pkl\")\n",
    "#y_test = pd.read_pickle(\"data/processed/ex2_y_test_20240512-155504.pkl\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Clean Data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-13 19:07:32 [\u001B[34msrc.data_cleaning:28\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Found 0 features with missing values above the threshold of 0.1.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_features = identify_missing_values(X_train, threshold=0.1)\n",
    "missing_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T17:07:32.168986100Z",
     "start_time": "2024-05-13T17:07:32.014434800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-13 19:07:34 [\u001B[34msrc.data_cleaning:48\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Found 45 features with only a single unique value.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "['Operation Setting 3__median',\n 'Operation Setting 3__mean',\n 'Operation Setting 3__standard_deviation',\n 'Operation Setting 3__variance',\n 'Operation Setting 3__root_mean_square',\n 'Operation Setting 3__maximum',\n 'Operation Setting 3__absolute_maximum',\n 'Operation Setting 3__minimum',\n 'Sensor Measure 1__median',\n 'Sensor Measure 1__mean',\n 'Sensor Measure 1__standard_deviation',\n 'Sensor Measure 1__variance',\n 'Sensor Measure 1__maximum',\n 'Sensor Measure 1__absolute_maximum',\n 'Sensor Measure 1__minimum',\n 'Sensor Measure 5__median',\n 'Sensor Measure 5__maximum',\n 'Sensor Measure 5__absolute_maximum',\n 'Sensor Measure 5__minimum',\n 'Sensor Measure 6__maximum',\n 'Sensor Measure 6__absolute_maximum',\n 'Sensor Measure 10__median',\n 'Sensor Measure 10__maximum',\n 'Sensor Measure 10__absolute_maximum',\n 'Sensor Measure 10__minimum',\n 'Sensor Measure 16__median',\n 'Sensor Measure 16__maximum',\n 'Sensor Measure 16__absolute_maximum',\n 'Sensor Measure 16__minimum',\n 'Sensor Measure 18__median',\n 'Sensor Measure 18__mean',\n 'Sensor Measure 18__standard_deviation',\n 'Sensor Measure 18__variance',\n 'Sensor Measure 18__root_mean_square',\n 'Sensor Measure 18__maximum',\n 'Sensor Measure 18__absolute_maximum',\n 'Sensor Measure 18__minimum',\n 'Sensor Measure 19__median',\n 'Sensor Measure 19__mean',\n 'Sensor Measure 19__standard_deviation',\n 'Sensor Measure 19__variance',\n 'Sensor Measure 19__root_mean_square',\n 'Sensor Measure 19__maximum',\n 'Sensor Measure 19__absolute_maximum',\n 'Sensor Measure 19__minimum']"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_unique_features = identify_single_unique_features(X_train)\n",
    "single_unique_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T17:07:34.428589200Z",
     "start_time": "2024-05-13T17:07:34.254461100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# drop features with missing values\n",
    "X_train.drop(columns=missing_features, inplace=True)\n",
    "X_test.drop(columns=missing_features, inplace=True)\n",
    "# drop features with single unique values\n",
    "X_train.drop(columns=single_unique_features, inplace=True)\n",
    "X_test.drop(columns=single_unique_features, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Feature Selection\n",
    "\n",
    "Orientation:\n",
    "![Feature Selection](https://machinelearningmastery.com/wp-content/uploads/2019/11/How-to-Choose-Feature-Selection-Methods-For-Machine-Learning.png)\n",
    "\n",
    "Potential Feature Selection Methods:\n",
    "* Supervised:\n",
    "    * Filter Methods:\n",
    "        * Numerical Input, Numerical Output:\n",
    "                * Pearsonâ€™s correlation coefficient (linear)\n",
    "                * Spearmanâ€™s rank coefficient (nonlinear)\n",
    "        * --> Using Pearsonâ€™s Correlation Coefficient via the f_regression() function and SelectKBest class."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
