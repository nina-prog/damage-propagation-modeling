{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:37.900316500Z",
     "start_time": "2024-05-09T15:31:37.830560800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:37.980322700Z",
     "start_time": "2024-05-09T15:31:37.900316500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Topic: EX2 - Turbofan RUL Prediction\n",
    "**Task**: Predict the remaining useful life (RUL) of turbofan engines based on given sensor data (time series data). It is a forcasting problem, where the goal is to predict the number of cycles an engine will last before it fails.\n",
    "**Data**: Turbofan engine degradation simulation data (NASA) - [Link](https://data.nasa.gov/dataset/Turbofan-Engine-Degradation-Simulation-Data-Set/vrks-gjie). See also in the topic [introduction notebook](https://github.com/nina-prog/damage-propagation-modeling/blob/2fb8c1a1102a48d7abbf04e4031807790a913a99/notebooks/Turbofan%20remaining%20useful%20life%20Prediction.ipynb).\n",
    "\n",
    "**Subtasks**:\n",
    "1. Perform a deep **exploratory data analysis (EDA)** on the given data.\n",
    "2. Implement a more efficient **sliding window method** for time series data analysis. -> üéØ **Focus on this task**\n",
    "3. Apply **traditional machine learning methods** (SOTA) to predict the remaining useful life. Includes data preparation, feature extraction, feature selection, model selection, and model parameter optimization.\n",
    "4. Create **neural network models** to predict the remaining useful life. Includes different architectures like Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), or Attention Models. Note: You can search for SOTA research papers and reproduce current state-of-the-art models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports + Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:38.193478100Z",
     "start_time": "2024-05-09T15:31:37.980322700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# third-party libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:38.400456500Z",
     "start_time": "2024-05-09T15:31:38.304026600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Set2\")\n",
    "sns.set(rc={\"figure.dpi\":100, 'savefig.dpi':200})\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:38.492590100Z",
     "start_time": "2024-05-09T15:31:38.400456500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/frbroy/Library/Mobile Documents/com~apple~CloudDocs/KIT/SoSe2024/PSDA/damage-propagation-modeling'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to execute this cell only once for one kernel session, before running any other cell below.\n",
    "os.chdir(\"../\") # set working directory to root of project\n",
    "os.getcwd() # check current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:38.652221700Z",
     "start_time": "2024-05-09T15:31:38.560578800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# source code\n",
    "from src.utils import load_data, load_config, train_val_split_by_group\n",
    "from src.data_preprocessing import calculate_RUL\n",
    "PATH_TO_CONFIG = \"configs/config.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load Config + Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:38.732034900Z",
     "start_time": "2024-05-09T15:31:38.652221700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = load_config(PATH_TO_CONFIG) # config is dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:39.154853100Z",
     "start_time": "2024-05-09T15:31:38.740553100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 00:14:34 [\u001b[34msrc.utils:62\u001b[0m] [\u001b[32mINFO\u001b[0m] >>>> Loading data set 1...\u001b[0m\n",
      "2024-05-17 00:14:34 [\u001b[34msrc.utils:91\u001b[0m] [\u001b[32mINFO\u001b[0m] >>>> Loaded raw data for dataset 1.\u001b[0m\n",
      "2024-05-17 00:14:34 [\u001b[34msrc.utils:92\u001b[0m] [\u001b[32mINFO\u001b[0m] >>>> Train Data: (20631, 26)\u001b[0m\n",
      "2024-05-17 00:14:34 [\u001b[34msrc.utils:93\u001b[0m] [\u001b[32mINFO\u001b[0m] >>>> Test Data: (13096, 26)\u001b[0m\n",
      "2024-05-17 00:14:34 [\u001b[34msrc.utils:94\u001b[0m] [\u001b[32mINFO\u001b[0m] >>>> Test RUL Data: (100, 1)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, test_data_RUL = load_data(config_path=PATH_TO_CONFIG, dataset_num=1)\n",
    "train_data = calculate_RUL(train_data, time_column= \"Cycle\", group_column= \"UnitNumber\")\n",
    "\n",
    "#train_data, val_data = train_val_split_by_group(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# üìç << Subtask NN: Try out NN Architecture >>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[TEMPLATE]\n",
    "\n",
    "Findings:\n",
    "* Interpretation of plots\n",
    "* or other key take aways from previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitNumber</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>Operation Setting 1</th>\n",
       "      <th>Operation Setting 2</th>\n",
       "      <th>Operation Setting 3</th>\n",
       "      <th>Sensor Measure 1</th>\n",
       "      <th>Sensor Measure 2</th>\n",
       "      <th>Sensor Measure 3</th>\n",
       "      <th>Sensor Measure 4</th>\n",
       "      <th>Sensor Measure 5</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor Measure 13</th>\n",
       "      <th>Sensor Measure 14</th>\n",
       "      <th>Sensor Measure 15</th>\n",
       "      <th>Sensor Measure 16</th>\n",
       "      <th>Sensor Measure 17</th>\n",
       "      <th>Sensor Measure 18</th>\n",
       "      <th>Sensor Measure 19</th>\n",
       "      <th>Sensor Measure 20</th>\n",
       "      <th>Sensor Measure 21</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UnitNumber  Cycle  Operation Setting 1  Operation Setting 2  \\\n",
       "0           1      1              -0.0007              -0.0004   \n",
       "1           1      2               0.0019              -0.0003   \n",
       "2           1      3              -0.0043               0.0003   \n",
       "3           1      4               0.0007               0.0000   \n",
       "4           1      5              -0.0019              -0.0002   \n",
       "\n",
       "   Operation Setting 3  Sensor Measure 1  Sensor Measure 2  Sensor Measure 3  \\\n",
       "0                100.0            518.67            641.82           1589.70   \n",
       "1                100.0            518.67            642.15           1591.82   \n",
       "2                100.0            518.67            642.35           1587.99   \n",
       "3                100.0            518.67            642.35           1582.79   \n",
       "4                100.0            518.67            642.37           1582.85   \n",
       "\n",
       "   Sensor Measure 4  Sensor Measure 5  ...  Sensor Measure 13  \\\n",
       "0           1400.60             14.62  ...            2388.02   \n",
       "1           1403.14             14.62  ...            2388.07   \n",
       "2           1404.20             14.62  ...            2388.03   \n",
       "3           1401.87             14.62  ...            2388.08   \n",
       "4           1406.22             14.62  ...            2388.04   \n",
       "\n",
       "   Sensor Measure 14  Sensor Measure 15  Sensor Measure 16  Sensor Measure 17  \\\n",
       "0            8138.62             8.4195               0.03                392   \n",
       "1            8131.49             8.4318               0.03                392   \n",
       "2            8133.23             8.4178               0.03                390   \n",
       "3            8133.83             8.3682               0.03                392   \n",
       "4            8133.80             8.4294               0.03                393   \n",
       "\n",
       "   Sensor Measure 18  Sensor Measure 19  Sensor Measure 20  Sensor Measure 21  \\\n",
       "0               2388              100.0              39.06            23.4190   \n",
       "1               2388              100.0              39.00            23.4236   \n",
       "2               2388              100.0              38.95            23.3442   \n",
       "3               2388              100.0              38.88            23.3739   \n",
       "4               2388              100.0              38.90            23.4044   \n",
       "\n",
       "   RUL  \n",
       "0  192  \n",
       "1  191  \n",
       "2  190  \n",
       "3  189  \n",
       "4  188  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scale Data Min Max\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def scale_data(df):\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    float_columns = df.select_dtypes(include=float).columns.tolist()\n",
    "    scaled_data = scaler.fit_transform(df[float_columns])\n",
    "    df[float_columns] = scaled_data\n",
    "\n",
    "    return df\n",
    "\n",
    "## create sliding window\n",
    "def create_sliding_window(df, window_size = 30, drop_columns = [\"UnitNumber\", \"Cycle\", \"RUL\"]):\n",
    "    \n",
    "    number_engines = df[\"UnitNumber\"].unique()\n",
    "    X, y = [], []\n",
    "\n",
    "    for engine in number_engines:\n",
    "\n",
    "        ## get all data with engine same engine type\n",
    "        temp = df[df[\"UnitNumber\"] == engine]\n",
    "        assert temp[\"UnitNumber\"].unique() == engine\n",
    "\n",
    "        ## loop over group\n",
    "        for i in range(len(temp) - window_size + 1):\n",
    "\n",
    "            X_temp = temp.iloc[i : (i + window_size)].drop(columns = drop_columns)\n",
    "            Y_temp = temp.iloc[(i + window_size - 1)][\"RUL\"]\n",
    "            assert len(X_temp) == 30\n",
    "            X.append(X_temp.to_numpy())\n",
    "            y.append(Y_temp)\n",
    "            if i == (len(temp) - window_size):\n",
    "                assert Y_temp == 1\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def scale_data(df):\n",
    "    \"\"\"\n",
    "    Scales the numerical columns in the DataFrame using MinMaxScaler.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Scaled DataFrame.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Select float columns\n",
    "    float_columns = df.select_dtypes(include=float).columns.tolist()\n",
    "    \n",
    "    # Scale the data\n",
    "    scaled_data = scaler.fit_transform(df[float_columns])\n",
    "    \n",
    "    # Update the DataFrame with scaled data\n",
    "    df[float_columns] = scaled_data\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_sliding_window(df, window_size=30, drop_columns=[\"UnitNumber\", \"Cycle\", \"RUL\"]):\n",
    "    \"\"\"\n",
    "    Creates a sliding window of data for time series prediction.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Input DataFrame containing time series data.\n",
    "        window_size (int): Size of the sliding window.\n",
    "        drop_columns (list): List of columns to drop from the input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing X (input) and y (output) arrays.\n",
    "    \"\"\"\n",
    "    number_engines = df[\"UnitNumber\"].unique()\n",
    "    X, y = [], []\n",
    "\n",
    "    for engine in number_engines:\n",
    "        # Get data for the current engine\n",
    "        temp = df[df[\"UnitNumber\"] == engine]\n",
    "        assert temp[\"UnitNumber\"].unique() == engine\n",
    "\n",
    "        for i in range(len(temp) - window_size + 1):\n",
    "            # Extract windowed data and RUL for each window\n",
    "            X_temp = temp.iloc[i : (i + window_size)].drop(columns=drop_columns)\n",
    "            Y_temp = temp.iloc[(i + window_size - 1)][\"RUL\"]\n",
    "            assert len(X_temp) == window_size\n",
    "            X.append(X_temp.to_numpy())\n",
    "            y.append(Y_temp)\n",
    "            if i == (len(temp) - window_size):\n",
    "                assert Y_temp == 1\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = scale_data(train_data)\n",
    "X_train, y_train = create_sliding_window(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:39.220343800Z",
     "start_time": "2024-05-09T15:31:39.160435700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [TEMPLATE] - save processed data (as pickle)\n",
    "df = pd.DataFrame()\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "df.to_pickle(f\"{config['paths']['processed_data_dir']}ex2_topic_{timestamp}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:39.318667400Z",
     "start_time": "2024-05-09T15:31:39.220343800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [TEMPLATE] - save data predictions (as csv)\n",
    "df = pd.DataFrame()\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "df.to_csv(f\"{config['paths']['prediction_dir']}ex2_topic_{timestamp}.csv\", sep=',', decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:39.485116500Z",
     "start_time": "2024-05-09T15:31:39.320350800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 900x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [TEMPLATE] - save plot results (as png)\n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "fig.savefig(f\"{config['paths']['plot_dir']}ex2_topic_{timestamp}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:39.522027500Z",
     "start_time": "2024-05-09T15:31:39.474058600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
