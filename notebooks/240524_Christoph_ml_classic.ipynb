{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:37.900316500Z",
     "start_time": "2024-05-09T15:31:37.830560800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:37.980322700Z",
     "start_time": "2024-05-09T15:31:37.900316500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Topic: EX2 - Turbofan RUL Prediction\n",
    "**Task**: Predict the remaining useful life (RUL) of turbofan engines based on given sensor data (time series data). It is a forcasting problem, where the goal is to predict the number of cycles an engine will last before it fails.\n",
    "**Data**: Turbofan engine degradation simulation data (NASA) - [Link](https://data.nasa.gov/dataset/Turbofan-Engine-Degradation-Simulation-Data-Set/vrks-gjie). See also in the topic [introduction notebook](https://github.com/nina-prog/damage-propagation-modeling/blob/2fb8c1a1102a48d7abbf04e4031807790a913a99/notebooks/Turbofan%20remaining%20useful%20life%20Prediction.ipynb).\n",
    "\n",
    "**Subtasks**:\n",
    "1. Perform a deep **exploratory data analysis (EDA)** on the given data.\n",
    "2. Implement a more efficient **sliding window method** for time series data analysis. -> 🎯 **Focus on this task**\n",
    "3. Apply **traditional machine learning methods** (SOTA) to predict the remaining useful life. Includes data preparation, feature extraction, feature selection, model selection, and model parameter optimization.\n",
    "4. Create **neural network models** to predict the remaining useful life. Includes different architectures like Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), or Attention Models. Note: You can search for SOTA research papers and reproduce current state-of-the-art models.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports + Settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# third-party libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html; Examples on how to approach classic classifiers\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "# previous\n",
    "from sklearn.metrics import accuracy_score,f1_score, root_mean_squared_error\n",
    "from sklearn.svm import SVC\n",
    "from bayes_opt import BayesianOptimization\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T08:45:46.266703Z",
     "start_time": "2024-05-25T08:45:46.250232Z"
    }
   },
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "source": [
    "# source code\n",
    "from src.utils import load_data, load_config\n",
    "from src.data_cleaning import clean_data, format_dtype\n",
    "from src.rolling_window_creator import calculate_RUL, RollingWindowDatasetCreator\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T17:03:32.812703Z",
     "start_time": "2024-05-24T17:03:32.784820Z"
    }
   },
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "# settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Set2\")\n",
    "sns.set(rc={\"figure.dpi\":100, 'savefig.dpi':200})\n",
    "sns.set_context('notebook')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T16:14:25.938585Z",
     "start_time": "2024-05-24T16:14:25.918902Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "np.random.seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T16:14:27.836023Z",
     "start_time": "2024-05-24T16:14:27.819031Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Make sure to execute this cell only once for one kernel session, before running any other cell below.\n",
    "os.chdir(\"../\") # set working directory to root of project\n",
    "os.getcwd() # check current working directory"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T16:14:46.691376Z",
     "start_time": "2024-05-24T16:14:46.676730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Christoph\\\\PycharmProjects\\\\damage-propagation-modeling_ml_classic'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "PATH_TO_CONFIG = \"configs/config.yaml\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T16:14:49.074990Z",
     "start_time": "2024-05-24T16:14:49.063046Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Config + Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "config = load_config(PATH_TO_CONFIG) # config is dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T16:14:52.195523Z",
     "start_time": "2024-05-24T16:14:52.170809Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "train_data, test_data,test_rul_data = load_data(config_path=PATH_TO_CONFIG, dataset_num=1)\n",
    "train_data_2, test_data_2,test_rul_data_2 = load_data(config_path=PATH_TO_CONFIG, dataset_num=2)\n",
    "train_data_3, test_data_3,test_rul_data_3 = load_data(config_path=PATH_TO_CONFIG, dataset_num=3)\n",
    "train_data_4, test_data_4,test_rul_data_4 = load_data(config_path=PATH_TO_CONFIG, dataset_num=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T09:50:52.441823Z",
     "start_time": "2024-05-25T09:50:48.777637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-25 11:50:48 [\u001B[34msrc.utils:60\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Loading data set 1...\u001B[0m\n",
      "2024-05-25 11:50:49 [\u001B[34msrc.utils:89\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Loaded raw data for dataset 1.\u001B[0m\n",
      "2024-05-25 11:50:49 [\u001B[34msrc.utils:90\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Train Data: (20631, 26)\u001B[0m\n",
      "2024-05-25 11:50:49 [\u001B[34msrc.utils:91\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Test Data: (13096, 26)\u001B[0m\n",
      "2024-05-25 11:50:49 [\u001B[34msrc.utils:92\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Test RUL Data: (100, 1)\u001B[0m\n",
      "2024-05-25 11:50:49 [\u001B[34msrc.utils:60\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Loading data set 2...\u001B[0m\n",
      "2024-05-25 11:50:50 [\u001B[34msrc.utils:89\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Loaded raw data for dataset 2.\u001B[0m\n",
      "2024-05-25 11:50:50 [\u001B[34msrc.utils:90\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Train Data: (53759, 26)\u001B[0m\n",
      "2024-05-25 11:50:50 [\u001B[34msrc.utils:91\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Test Data: (33991, 26)\u001B[0m\n",
      "2024-05-25 11:50:50 [\u001B[34msrc.utils:92\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Test RUL Data: (259, 1)\u001B[0m\n",
      "2024-05-25 11:50:50 [\u001B[34msrc.utils:60\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Loading data set 3...\u001B[0m\n",
      "2024-05-25 11:50:50 [\u001B[34msrc.utils:89\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Loaded raw data for dataset 3.\u001B[0m\n",
      "2024-05-25 11:50:50 [\u001B[34msrc.utils:90\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Train Data: (24720, 26)\u001B[0m\n",
      "2024-05-25 11:50:50 [\u001B[34msrc.utils:91\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Test Data: (16596, 26)\u001B[0m\n",
      "2024-05-25 11:50:50 [\u001B[34msrc.utils:92\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Test RUL Data: (100, 1)\u001B[0m\n",
      "2024-05-25 11:50:50 [\u001B[34msrc.utils:60\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Loading data set 4...\u001B[0m\n",
      "2024-05-25 11:50:52 [\u001B[34msrc.utils:89\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Loaded raw data for dataset 4.\u001B[0m\n",
      "2024-05-25 11:50:52 [\u001B[34msrc.utils:90\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Train Data: (61249, 26)\u001B[0m\n",
      "2024-05-25 11:50:52 [\u001B[34msrc.utils:91\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Test Data: (41214, 26)\u001B[0m\n",
      "2024-05-25 11:50:52 [\u001B[34msrc.utils:92\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Test RUL Data: (248, 1)\u001B[0m\n",
      "CPU times: total: 734 ms\n",
      "Wall time: 3.65 s\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "source": "# 📍 << Task 2: Classic Machine learning >>",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[TEMPLATE]\n",
    "\n",
    "Findings:\n",
    "* Interpretation of plots\n",
    "* or other key take aways from previous code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# [TEMPLATE] - save processed data (as pickle)\n",
    "df = pd.DataFrame()\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "df.to_pickle(f\"{config['paths']['processed_data_dir']}ex2_topic_{timestamp}.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T16:56:56.959882Z",
     "start_time": "2024-05-24T16:56:56.942913Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# [TEMPLATE] - save data predictions (as csv)\n",
    "df = pd.DataFrame()\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "df.to_csv(f\"{config['paths']['prediction_dir']}ex2_topic_{timestamp}.csv\", sep=',', decimal='.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:39.318667400Z",
     "start_time": "2024-05-09T15:31:39.220343800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 900x600 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [TEMPLATE] - save plot results (as png)\n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "fig.savefig(f\"{config['paths']['plot_dir']}ex2_topic_{timestamp}.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:39.485116500Z",
     "start_time": "2024-05-09T15:31:39.320350800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": "",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T15:31:39.522027500Z",
     "start_time": "2024-05-09T15:31:39.474058600Z"
    }
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Use the created in advanced functions to remove non-helpful data as determined by the EDA \n",
    "(Currently without outlier removal)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T07:31:10.130115Z",
     "start_time": "2024-05-25T07:31:10.107363Z"
    }
   },
   "cell_type": "code",
   "source": "train_data = format_dtype(train_data)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-25 09:31:10 [\u001B[34msrc.data_cleaning:69\u001B[0m] [DEBUG\u001B[0m] >>>> Found 0 categorical columns: []\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T17:01:43.955999Z",
     "start_time": "2024-05-24T17:01:43.815061Z"
    }
   },
   "cell_type": "code",
   "source": "cleaned_train, cleaned_test = clean_data(train_data, test_data, method=None, ignore_columns=['UnitNumber', 'Cycle'], threshold_missing=0.1, threshold_corr=0.3)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-24 19:01:43 [\u001B[34msrc.data_cleaning:134\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Cleaning train and test data...\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.data_cleaning:136\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Formatting column types...\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.data_cleaning:69\u001B[0m] [DEBUG\u001B[0m] >>>> Found 0 categorical columns: []\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.data_cleaning:69\u001B[0m] [DEBUG\u001B[0m] >>>> Found 0 categorical columns: []\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.data_cleaning:141\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Handling duplicates...\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.data_cleaning:146\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Removing outliers...\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.outlier_detection:150\u001B[0m] [DEBUG\u001B[0m] >>>> Removing outliers using method: None ...\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.outlier_detection:162\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> No outlier detection method specified. Skipping outlier detection.\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.outlier_detection:150\u001B[0m] [DEBUG\u001B[0m] >>>> Removing outliers using method: None ...\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.outlier_detection:162\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> No outlier detection method specified. Skipping outlier detection.\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.data_cleaning:150\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Filter features based train data...\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.data_cleaning:26\u001B[0m] [DEBUG\u001B[0m] >>>> Found 0 features with missing values above the threshold of 0.1.\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.data_cleaning:46\u001B[0m] [DEBUG\u001B[0m] >>>> Found 7 features with only a single unique value: ['Operation Setting 3', 'Sensor Measure 1', 'Sensor Measure 5', 'Sensor Measure 10', 'Sensor Measure 16', 'Sensor Measure 18', 'Sensor Measure 19']\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.data_cleaning:103\u001B[0m] [DEBUG\u001B[0m] >>>> Found 4 uncorrelated features with a correlation threshold of 0.3: ['UnitNumber', 'Operation Setting 1', 'Operation Setting 2', 'Sensor Measure 6']\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.data_cleaning:162\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Dropping features based on missing values, single unique values, and no target correlation...\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.data_cleaning:172\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Data cleaning completed.\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.data_cleaning:173\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Original train DataFrame shape: (20631, 16), Resulting train DataFrame shape: (20631, 16)\u001B[0m\n",
      "2024-05-24 19:01:43 [\u001B[34msrc.data_cleaning:174\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Original test DataFrame shape: (13096, 16), Resulting test DataFrame shape: (13096, 16)\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T07:28:50.202617Z",
     "start_time": "2024-05-25T07:28:50.181633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(cleaned_train.shape)\n",
    "print(cleaned_test.columns)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 16)\n",
      "Index(['UnitNumber', 'Cycle', 'Sensor Measure 2', 'Sensor Measure 3',\n",
      "       'Sensor Measure 4', 'Sensor Measure 7', 'Sensor Measure 8',\n",
      "       'Sensor Measure 9', 'Sensor Measure 11', 'Sensor Measure 12',\n",
      "       'Sensor Measure 13', 'Sensor Measure 14', 'Sensor Measure 15',\n",
      "       'Sensor Measure 17', 'Sensor Measure 20', 'Sensor Measure 21'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Choose a set of feature options for tsfresh windowing\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T08:32:06.182189Z",
     "start_time": "2024-05-25T08:32:06.164895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Currently using minimal to ease optimization so feature_list is not necessary\n",
    "feature_list = []\n",
    "\n",
    "# feature_list for dataset 1\n",
    "# TODO: create function to make variable for each dataset to ease optimization\n",
    "currentpath = os.getcwd()\n",
    "ft_list = pd.read_pickle(currentpath+ \"/data/processed/dataset1_remaining_features_0521.pkl\")"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T08:13:52.957058Z",
     "start_time": "2024-05-25T08:13:52.951635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "min_ts = 5\n",
    "max_ts = 20"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Windowing\n",
    "\n",
    "via tsfresh"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T08:13:58.793194Z",
     "start_time": "2024-05-25T08:13:58.772835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rwCreator = RollingWindowDatasetCreator(max_timeshift=max_ts,min_timeshift=min_ts,feature_extraction_mode= 'minimal')\n",
    "# feature_list=feature_list"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T08:15:49.782675Z",
     "start_time": "2024-05-25T08:14:00.979457Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, y_train, X_test, y_test = rwCreator.create_rolling_windows_datasets(train_data=cleaned_train, test_data=cleaned_test,test_RUL_data=test_rul_data,)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-25 10:14:00 [\u001B[34msrc.rolling_window_creator:117\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Creating rolling windows for train data...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|██████████| 20/20 [00:12<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-25 10:14:14 [\u001B[34msrc.rolling_window_creator:123\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Extracting features for train data...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [01:13<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-25 10:15:35 [\u001B[34msrc.rolling_window_creator:131\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Calculating target for train data...\u001B[0m\n",
      "2024-05-25 10:15:35 [\u001B[34msrc.rolling_window_creator:117\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Creating rolling windows for test data...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|██████████| 19/19 [00:08<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-25 10:15:44 [\u001B[34msrc.rolling_window_creator:123\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Extracting features for test data...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [00:04<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-25 10:15:49 [\u001B[34msrc.rolling_window_creator:159\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Datasets created successfully.\u001B[0m\n",
      "2024-05-25 10:15:49 [\u001B[34msrc.rolling_window_creator:160\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Shape of X_train: (20131, 140)\u001B[0m\n",
      "2024-05-25 10:15:49 [\u001B[34msrc.rolling_window_creator:161\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Shape of y_train: (20131, 1)\u001B[0m\n",
      "2024-05-25 10:15:49 [\u001B[34msrc.rolling_window_creator:162\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Shape of X_test: (100, 140)\u001B[0m\n",
      "2024-05-25 10:15:49 [\u001B[34msrc.rolling_window_creator:163\u001B[0m] [\u001B[32mINFO\u001B[0m] >>>> Shape of y_test: (100, 1)\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scaling\n",
    "\n",
    "- StandardScaler"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T08:38:59.259070Z",
     "start_time": "2024-05-25T08:38:59.250272Z"
    }
   },
   "cell_type": "code",
   "source": "scaler = StandardScaler()",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T08:37:20.930613Z",
     "start_time": "2024-05-25T08:37:20.808977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature Selection\n",
    "\n",
    "- RFE\n",
    "- SimpleCorrApproach"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Models\n",
    "- RandomForestClassifier\n",
    "- SVC\n",
    "- MLP\n",
    "- GPC\n",
    "- KNeighboursClassifier\n",
    "- Gaussian Naive Bayes\n",
    "- AdaBoostClassifier\n",
    "- QuadraticDiscrimantAnalysis\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T08:39:02.866142Z",
     "start_time": "2024-05-25T08:39:02.849168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    SVC(gamma=2, C=1, random_state=42),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "    ),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n",
    "    AdaBoostClassifier(algorithm=\"SAMME\", random_state=42),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    \n",
    "]"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training & Evaluation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T08:56:26.185078Z",
     "start_time": "2024-05-25T08:56:26.178703Z"
    }
   },
   "cell_type": "code",
   "source": "type(y_train.values.ravel())",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T09:48:10.073301Z",
     "start_time": "2024-05-25T09:44:56.837234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for clf in classifiers:\n",
    "    \n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print(sklearn.metrics.root_mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    #rmse = sklearn.model_selection.cross_val_score(clf, X=X_train, y=y_train, cv=5, scoring='root_mean_squared_error')\n",
    "    #print(rmse)\n",
    "    "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1860.81\n",
      "1189.98\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[92], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m clf \u001B[38;5;129;01min\u001B[39;00m classifiers:\n\u001B[1;32m----> 3\u001B[0m     \u001B[43mclf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mravel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m clf\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(sklearn\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mmean_squared_error(y_test, y_pred))\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1472\u001B[0m     )\n\u001B[0;32m   1473\u001B[0m ):\n\u001B[1;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:250\u001B[0m, in \u001B[0;36mBaseLibSVM.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    247\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LibSVM]\u001B[39m\u001B[38;5;124m\"\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    249\u001B[0m seed \u001B[38;5;241m=\u001B[39m rnd\u001B[38;5;241m.\u001B[39mrandint(np\u001B[38;5;241m.\u001B[39miinfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mi\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mmax)\n\u001B[1;32m--> 250\u001B[0m \u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msolver_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    251\u001B[0m \u001B[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001B[39;00m\n\u001B[0;32m    253\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape_fit_ \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(X, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m (n_samples,)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:329\u001B[0m, in \u001B[0;36mBaseLibSVM._dense_fit\u001B[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001B[0m\n\u001B[0;32m    315\u001B[0m libsvm\u001B[38;5;241m.\u001B[39mset_verbosity_wrap(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[0;32m    317\u001B[0m \u001B[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001B[39;00m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;66;03m# add other parameters to __init__\u001B[39;00m\n\u001B[0;32m    319\u001B[0m (\n\u001B[0;32m    320\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupport_,\n\u001B[0;32m    321\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupport_vectors_,\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_support,\n\u001B[0;32m    323\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdual_coef_,\n\u001B[0;32m    324\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept_,\n\u001B[0;32m    325\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_probA,\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_probB,\n\u001B[0;32m    327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_status_,\n\u001B[0;32m    328\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_iter,\n\u001B[1;32m--> 329\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[43mlibsvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    330\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    331\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    332\u001B[0m \u001B[43m    \u001B[49m\u001B[43msvm_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    333\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    334\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mclass_weight_\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    335\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkernel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    336\u001B[0m \u001B[43m    \u001B[49m\u001B[43mC\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mC\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    337\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnu\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    338\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprobability\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprobability\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    339\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdegree\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdegree\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    340\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshrinking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshrinking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    341\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    342\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    343\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcoef0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoef0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgamma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gamma\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    345\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepsilon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepsilon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    347\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_seed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_warn_from_fit_status()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## First Observations\n",
    "\n",
    "Size is too big -> notebook outsourced to colab \n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Optimizations\n",
    "\n",
    "-- TODO -- "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def hyperparameter_function(clf):\n",
    "    ''' Hyperparameter Opti\n",
    "    '''\n",
    "    classifier = clf\n",
    "    rmse = sklearn.model_selection.cross_val_score(classifier, X=X_train, y=y_train, cv=5, scoring='root_mean_squared_error')\n",
    "    return rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
