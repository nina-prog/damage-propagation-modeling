{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "## utils \n",
    "def load_config(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "def load_dataset(config: Dict, typ: str = \"train\", number_file: str = \"001\") -> pd.DataFrame:\n",
    "    # Motornummer, Zeitschritt\n",
    "    index_columns_names: List[str] =  [\"UnitNumber\",\"Cycle\"]\n",
    "    # 3 betriebsbereite Sensoreinstellungen\n",
    "    operational_settings_columns_names: List[str] = [\"Operation Setting \"+str(i) for i in range(1,4)]\n",
    "    # 21 Sensormessungen\n",
    "    sensor_measure_columns_names: List[str] = [\"Sensor Measure\"+str(i) for i in range(1,22)]\n",
    "\n",
    "    input_file_column_names: List[str] = index_columns_names + operational_settings_columns_names + sensor_measure_columns_names\n",
    "    print(f\"In total {len(input_file_column_names)} columns defined as {input_file_column_names}\")\n",
    "\n",
    "    ###############################\n",
    "    ### load train data\n",
    "    if typ == \"train\":\n",
    "        type_path = config[\"dataloading\"][\"train_path\"]\n",
    "    elif typ == \"test\":\n",
    "        type_path = config[\"dataloading\"][\"train_path\"]\n",
    "    elif \"rul\" in typ.lower():\n",
    "        type_path = config[\"dataloading\"][\"RUL_path\"]\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    data: pd.DataFrame = pd.read_csv(config[\"dataloading\"][\"path_to_data\"] + config[\"dataloading\"][\"train_path\"] + number_file +'.txt', sep='\\s+', header=None)\n",
    "    data.columns = input_file_column_names\n",
    "    return data\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "###############################\n",
    "## imports\n",
    "###############################\n",
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set path \n",
    "os.chdir(\"../\")\n",
    "pd.set_option('display.max_columns', 500)\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "###############################\n",
    "## load config\n",
    "###############################\n",
    "config_file_path = './configs/config.yaml'\n",
    "config = load_config(config_file_path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "###############################\n",
    "## load data\n",
    "###############################\n",
    "train_data = load_dataset(config=config, typ=\"train\", number_file=\"001\")\n",
    "train_data.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "source": [
    "def min_max(values):\n",
    "    return values.max() - values.min()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "source": [
    "window_size = 3\n",
    "functs = [\"mean\", \"sum\", min_max]\n",
    "# Compute the rolling mean for each column\n",
    "rolling_mean = apply_rolling_window(train_data, window_size = window_size, functs=functs)\n",
    "\n",
    "rolling_mean.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "source": [
    "def apply_rolling_window(df, window_size, functs, exclude = [\"UnitNumber\", \"Cycle\"]):\n",
    "    # Exclude \"UnitNumber\" from the aggregation dictionary\n",
    "    \n",
    "    agg_dict = {col: functs for col in df.columns if col not in exclude}\n",
    "    \n",
    "    # Apply rolling window and aggregation grouped by \"UnitNumber\"\n",
    "    rolling_data = df.groupby(\"UnitNumber\").apply(lambda x: x.rolling(window=window_size).agg(agg_dict)).dropna()\n",
    "    \n",
    "    # Merge back \"UnitNumber\" to the dataset\n",
    "    rolling_data = rolling_data.reset_index()\n",
    "    rolling_data = rolling_data.drop(columns=[\"level_1\"])\n",
    "    rolling_data[\"Cycle\"] = df[\"Cycle\"]\n",
    "\n",
    "    ## refactor 2-levels of column names to only one level\n",
    "    rolling_data.columns = ['_'.join(col).strip() if col[1] != \"\" else col[0] for col in rolling_data.columns.values]\n",
    "    \n",
    "    return rolling_data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
